# -*- coding: utf-8 -*-
"""Home_Work_#5_Linear_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vtYmCt4aG3DNnVbtjUEwzHIM_QVhsK6r

### Preparing
"""

# !pip install featuretools

# from pandas.core.arrays.sparse.array import NaT
# import matplotlib.pyplot as plt
# import featuretools as ft
import pickle
import numpy as np
import pandas as pd
# from matplotlib.container import BarContainer
# from matplotlib.axes import Axes
# from pandas.core.groupby import DataFrameGroupBy
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet, Lasso
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import seaborn as sns
# import plotly.express as px


# np.random.seed(seed=1729)


def save_model_to_drive(model, model_name: str):
    # model_name: str = f"{model=}".split('=')[0]

    filename: str = f"{model_name}.pkl"

    with open(filename, "wb") as file:
        pickle.dump(model, file, pickle.HIGHEST_PROTOCOL)

def load_model(model_name):
    with open(model_name, "rb") as file:
      return pickle.load(file)


def mount_google_drive() -> bool | None:
    """
    Function to mount Google Drive.
    :return: True if mounting is successful, None otherwise.
    """
    try:
        from google.colab.drive import mount

        mount(mountpoint="/content/drive")
        return True

    except Exception as error:
        print(f"Error while mounting Google Drive: {error}")
        raise


def get_google_drive_dataset_path() -> tuple:
    """
    Function to retrieve the path of the raw dataset from Google Drive.
    :return: Path of raw dataset as a string.
    """
    return (
        "/content/drive/MyDrive/Hillel/Machine_Learning_Course/HW5/winequality-red.csv",
        "/content/drive/MyDrive/Hillel/Machine_Learning_Course/HW5/winequality-white.csv"
    )


def get_data_frame(dataset_path: str) -> tuple[pd.DataFrame] | None:
    """
    Function to convert the dataset into a pd.DataFrame.
    :param dataset_path: Path or URL of the dataset.
    :return: pd.DataFrame containing the dataset, or None if errors occur.
    """
    try:
        # return pd.read_csv(filepath_or_buffer=dataset_path)
        return pd.read_csv(filepath_or_buffer=dataset_path, sep=";")

    except Exception as error:
        print(f"Error while converting dataset to NumPy array: {error}")
        raise


def main() -> tuple[pd.DataFrame] | None:
    """
    Main function to start the app.
    :return: pd.DataFrame containing the dataset, or None if errors occur.
    """
    if mount_google_drive():
        import os

        datasets_paths: tuple = get_google_drive_dataset_path()
        if all(map(os.path.exists, datasets_paths)):
            data_frames: tuple = tuple(get_data_frame(dataset_path=path) for path in datasets_paths)

            return data_frames

        else:
            print("Dataset path doesn't exists.")
            raise FileNotFoundError


if __name__ == "__main__":
    raw_data_frames: tuple | None = main()
    if raw_data_frames:
      red_winequality_dataframe: pd.DataFrame = raw_data_frames[0]
      white_winequality_dataframe: pd.DataFrame = raw_data_frames[1]

def generate_features(features_list: list, dataframe: pd.DataFrame) -> pd.DataFrame:
  featured_dataframe: pd.DataFrame = dataframe.copy(deep=True)
  new_columns: list = []

  for feature1 in features_list:
    for feature2 in features_list:
      if feature1 == feature2:
        continue
      new_columns.append(pd.Series(data=(featured_dataframe[feature1] + featured_dataframe[feature2]), name=f"{feature1}+{feature2}"))
      new_columns.append(pd.Series(data=(featured_dataframe[feature1] * featured_dataframe[feature2]), name=f"{feature1}*{feature2}"))
      new_columns.append(pd.Series(data=(featured_dataframe[feature1] - featured_dataframe[feature2]), name=f"{feature1}_-_{feature2}"))
      new_columns.append(pd.Series(data=(featured_dataframe[feature1] / featured_dataframe[feature2]), name=f"{feature1}/{feature2}"))
      new_columns.append(pd.Series(data=(featured_dataframe[feature1].astype(bool) & featured_dataframe[feature2].astype(bool)), name=f"{feature1}_AND_{feature2}"))
      new_columns.append(pd.Series(data=(featured_dataframe[feature1].astype(bool) | featured_dataframe[feature2].astype(bool)), name=f"{feature1}_OR_{feature2}"))

  new_cols_df: pd.DataFrame = pd.concat(new_columns, axis=1)
  featured_dataframe: pd.DataFrame = pd.concat([featured_dataframe, new_cols_df], axis=1)

  return featured_dataframe

"""Для датасету

https://archive.ics.uci.edu/ml/datasets/wine+quality

побудувати **модель лінійної регресії**

Обов'язкові кроки:

*   первинний аналіз даних (відстуність пропусків, наявність категоріальних фіч, ...)  (+)
*   фича інжиніринг (побудувати 1-2 нові фічі) *5-10  (+)
*   масштабування фіч  (+)
*   поділ датасету на: (+)
  1. тренувальну,
  2. валідаційну
  3. тестову частини
*   тренування базової моделі із дефолтними гіперпараметрами (кожну модель) (+)
*   підбір гіперпараметрів (кожну модель) (+)
*   оцінка результатів (порівняння всіх на тестовій частині) !!!
*   порівняти коефіцієнти на стохастичному град спуску, і на алгебраїчному рішенні (+)
*   побудувати модель різними способами (GD, SGD, MBGD... perceptron, ...) (+)
*   метрики (+)

### Red Wine
"""

print("'"*100)
# red_winequality_dataframe.isnull().values.any()
red_winequality_dataframe.info()
print("'"*100)
red_winequality_dataframe.head(10)

main_columns: list = list(red_winequality_dataframe.columns.values)

### Создаэмо новий датасет з нагенерованими фічами:
new_red_wine_df: pd.DataFrame = generate_features(features_list=main_columns[:-1], dataframe=red_winequality_dataframe)
new_columns: list = list(new_red_wine_df.columns.values)

### Перевіряємо кореляцію, і видідяємо найзначніші фічі:
# correlations: pd.Series = new_red_wine_df.corr()["quality"]
# sorted_correlations: pd.Series = correlations.abs().sort_values(ascending=False)
# top_features: pd.Index = sorted_correlations.index[:11]

### визначили найзначніші фічі:
important_columns: list = ["volatile acidity_-_alcohol", "alcohol+sulphates", "citric acid+alcohol",
                           "alcohol/pH", "pH_-_alcohol", "pH/alcohol", "alcohol*density", "chlorides_-_alcohol", "alcohol+density"]

### залишаємо тільки дефолні, та нові найзначніші фічі які більш всього корелюють на таргет, залишок видаляємо.
columns_to_delete: list = set(new_columns) - (set(main_columns + important_columns))
new_red_wine_df: pd.DataFrame = new_red_wine_df.drop(labels=columns_to_delete, axis=1)
new_red_wine_df.info()

### Heatmap
new_red_wine_df_matrix = new_red_wine_df.corr()
# sns.heatmap(data=new_red_wine_df_matrix)
# sns.heatmap(data=new_red_wine_df_matrix, annot=True)

### Split dataset
red_wine_df_train_part, red_wine_df_test_validation_part = train_test_split(new_red_wine_df, test_size=0.2)
red_wine_df_validation_part, red_wine_df_test_part = train_test_split(red_wine_df_test_validation_part, test_size=0.33)

# red_wine_df_train_part.info()
# red_wine_df_validation_part.info()
# red_wine_df_test_part.info()

### FEATURES (X), and TARGET (Y)
train_features_X: pd.DataFrame = red_wine_df_train_part.drop("quality", axis=1)
train_target_y: pd.Series = red_wine_df_train_part["quality"]

validate_features_X: pd.DataFrame = red_wine_df_validation_part.drop("quality", axis=1)
validate_target_y: pd.Series = red_wine_df_validation_part["quality"]

test_features_X: pd.DataFrame = red_wine_df_test_part.drop("quality", axis=1)
test_target_y: pd.Series = red_wine_df_test_part["quality"]

### Common function to create models

def create_model(regressor, name:str, scaler, partial: bool = False):
  print("'"*50)
  print(f"         {name}")

  if partial:
    model = regressor.partial_fit(X=train_features_X, y=train_target_y)

  else:
    model: Pipeline = make_pipeline(scaler, regressor)
    model.fit(X=train_features_X, y=train_target_y)

  ## Attributes
  print(f"                     Score: {model.score(X=train_features_X, y=train_target_y)}")
  print(f"                     ''''''''''''''''''''''''''")

  ## Predict
  model_predict = model.predict(X=validate_features_X)

  ## Metrics
  model_r2: np.float64 = r2_score(y_true=validate_target_y, y_pred=model_predict)
  print(f"                        R2: {model_r2}")

  model_mean_squared_error: np.float64 = mean_squared_error(y_true=validate_target_y, y_pred=model_predict)
  print(f"  Mean_squared_error (MSE): {model_mean_squared_error}")

  model_mean_absolute_error: np.float64 = mean_absolute_error(y_true=validate_target_y, y_pred=model_predict)
  print(f" Mean_absolute_error (MAE): {model_mean_absolute_error}")

  print("'"*50)
  return model

  # save_model_to_drive(model=model, model_name=f"{str(model_r2)[:6]}{name}")

def value_results(model, name:str):
  print("'"*50)
  print(name)
  model_predict = model.predict(X=test_features_X)

  ## Metrics
  model_r2: np.float64 = r2_score(y_true=test_target_y, y_pred=model_predict)
  print(f"                        R2: {model_r2}")

  model_mean_squared_error: np.float64 = mean_squared_error(y_true=test_target_y, y_pred=model_predict)
  print(f"  Mean_squared_error (MSE): {model_mean_squared_error}")

  model_mean_absolute_error: np.float64 = mean_absolute_error(y_true=test_target_y, y_pred=model_predict)
  print(f" Mean_absolute_error (MAE): {model_mean_absolute_error}")
  print("'"*50)

## SCALER
red_wine_min_max_scaler: MinMaxScaler = MinMaxScaler().fit(X=red_wine_df_train_part)
# red_wine_standard_scaler: StandardScaler = StandardScaler().fit(X=red_wine_df_train_part)

### ****** LINEARREGRESSION. FOR RED WINE ******
red_wine_linear_clean_regressor: LinearRegression = create_model(
    regressor=LinearRegression(),
    name="red_wine_linear_clean_regressor",
    scaler=red_wine_min_max_scaler
)

### ****** LINEARREGRESSION WITH HYPER PARAMS. FOR RED WINE ******
red_wine_linear_hyper_params_regressor: LinearRegression = create_model(
    # regressor=LinearRegression(n_jobs=-1),
    # regressor=LinearRegression(positive=True),
    regressor=LinearRegression(fit_intercept=False),
    name="red_wine_linear_hyper_params_regressor",
    scaler=red_wine_min_max_scaler
)

### ****** SGDRegressor. FOR RED WINE ******
red_wine_clean_sgdegressor: SGDRegressor = create_model(
    regressor=SGDRegressor(),
    name="red_wine_clean_sgdegressor",
    scaler=red_wine_min_max_scaler
)

### ****** SGDRegressor WITH HYPER PARAMS. FOR RED WINE ******
red_wine_hyper_params_sgdegressor: SGDRegressor = create_model(
    regressor=SGDRegressor(loss="squared_epsilon_insensitive", penalty="elasticnet", tol=1e-5, n_iter_no_change=15), # better than clean
    name="red_wine_hyper_params_sgdegressor",
    scaler=red_wine_min_max_scaler
)

### ****** MINI BATCH SGDRegressor. FOR RED WINE ******
red_wine_clean_mb_sgdegressor: SGDRegressor = create_model(
    regressor=SGDRegressor(),
    name="red_wine_clean_mb_sgdegressor",
    scaler=red_wine_min_max_scaler,
    partial=True
)

### ****** MINI BATCH SGDRegressor WITH HYPER PARAMS. FOR RED WINE ******
red_wine_hyper_params_mb_sgdegressor: SGDRegressor = create_model(
    regressor=SGDRegressor(loss="squared_epsilon_insensitive", penalty="elasticnet", tol=1e-5, n_iter_no_change=15),
    name="red_wine_hyper_params_mb_sgdegressor",
    scaler=red_wine_min_max_scaler,
    partial=True
)

### ****** ElasticNet. FOR RED WINE ******
red_wine_clean_elastic_net: ElasticNet = create_model(
    regressor=ElasticNet(),
    name="red_wine_clean_elastic_net",
    scaler=red_wine_min_max_scaler
)

### ****** ElasticNet WITH HYPER PARAMS. FOR RED WINE ******
red_wine_hyper_params_elastic_net: ElasticNet = create_model(
    regressor=ElasticNet(tol=1e-8, l1_ratio=0.2),
    name="red_wine_hyper_params_elastic_net",
    scaler=red_wine_min_max_scaler
)

### ****** Lasso. FOR RED WINE ******
red_wine_clean_l1: Lasso = create_model(
    regressor=Lasso(),
    name="red_wine_clean_l1",
    scaler=red_wine_min_max_scaler
)

### ****** Lasso WITH HYPER PARAMS. FOR RED WINE ******
red_wine_hyper_params_l1: Lasso = create_model(
    regressor=Lasso(alpha=0.5, tol=1e-6),
    name="red_wine_hyper_params_l1",
    scaler=red_wine_min_max_scaler
)

### Оцінка результатів
value_results(model=red_wine_linear_clean_regressor, name="red_wine_linear_clean_regressor")
value_results(model=red_wine_linear_hyper_params_regressor, name="red_wine_linear_hyper_params_regressor")
value_results(model=red_wine_clean_sgdegressor, name="red_wine_clean_sgdegressor")
value_results(model=red_wine_hyper_params_sgdegressor, name="red_wine_hyper_params_sgdegressor")
value_results(model=red_wine_clean_mb_sgdegressor, name="red_wine_clean_mb_sgdegressor")
value_results(model=red_wine_hyper_params_mb_sgdegressor, name="red_wine_hyper_params_mb_sgdegressor")
value_results(model=red_wine_clean_elastic_net, name="red_wine_clean_elastic_net")
value_results(model=red_wine_hyper_params_elastic_net, name="red_wine_hyper_params_elastic_net")
value_results(model=red_wine_clean_l1, name="red_wine_clean_l1")
value_results(model=red_wine_hyper_params_l1, name="red_wine_hyper_params_l1")

"""### White Wine"""

print("'"*100)
# white_winequality_dataframe.isnull().values.any()
white_winequality_dataframe.info()
print("'"*100)
white_winequality_dataframe.head(10)

w_main_columns: list = list(white_winequality_dataframe.columns.values)

### Создаэмо новий датасет з нагенерованими фічами:
new_white_wine_df: pd.DataFrame = generate_features(features_list=w_main_columns[:-1], dataframe=white_winequality_dataframe)
new_columns: list = list(new_white_wine_df.columns.values)

### Перевіряємо кореляцію, і видідяємо найзначніші фічі:
# correlations: pd.Series = new_white_wine_df.corr()["quality"]
# sorted_correlations: pd.Series = correlations.abs().sort_values(ascending=False)
# top_features: pd.Index = sorted_correlations.index[:25]
# print(top_features)

# визначили найзначніші фічі:
w_important_columns: list = ["alcohol_-_volatile acidity", "sulphates+alcohol", "alcohol+pH",
                           "chlorides_-_alcohol", "density*alcohol", "alcohol+citric acid", "density+alcohol"]


### залишаємо тільки дефолні, та нові найзначніші фічі які більш всього корелюють на таргет, залишок видаляємо.
columns_to_delete: list = set(new_columns) - (set(w_main_columns + w_important_columns))
new_white_wine_df: pd.DataFrame = new_white_wine_df.drop(labels=columns_to_delete, axis=1)
new_white_wine_df.info()

### Heatmap
new_white_wine_df_matrix = new_white_wine_df.corr()
# sns.heatmap(data=new_white_wine_df_matrix)
# sns.heatmap(data=new_white_wine_df_matrix, annot=True)

### Split dataset
white_wine_df_train_part, white_wine_df_test_validation_part = train_test_split(new_white_wine_df, test_size=0.1)
white_wine_df_validation_part, white_wine_df_test_part = train_test_split(white_wine_df_test_validation_part, test_size=0.33)

# white_wine_df_train_part.info()
# white_wine_df_validation_part.info()
# white_wine_df_test_part.info()

### FEATURES (X), and TARGET (Y)
w_train_features_X: pd.DataFrame = white_wine_df_train_part.drop("quality", axis=1)
w_train_target_y: pd.Series = white_wine_df_train_part["quality"]

w_validate_features_X: pd.DataFrame = white_wine_df_validation_part.drop("quality", axis=1)
w_validate_target_y: pd.Series = white_wine_df_validation_part["quality"]

w_test_features_X: pd.DataFrame = white_wine_df_test_part.drop("quality", axis=1)
w_test_target_y: pd.Series = white_wine_df_test_part["quality"]

### Common function to create models

def w_create_model(regressor, name:str, scaler, partial: bool = False):
  print("'"*50)
  print(f"         {name}")

  if partial:
    model = regressor.partial_fit(X=w_train_features_X, y=w_train_target_y)

  else:
    model: Pipeline = make_pipeline(scaler, regressor)
    model.fit(X=w_train_features_X, y=w_train_target_y)

  ## Attributes
  print(f"                     Score: {model.score(X=w_train_features_X, y=w_train_target_y)}")
  print(f"                     ''''''''''''''''''''''''''")

  ## Predict
  model_predict = model.predict(X=w_validate_features_X)
  ## Metrics
  model_r2: np.float64 = r2_score(y_true=w_validate_target_y, y_pred=model_predict)
  print(f"                        R2: {model_r2}")

  model_mean_squared_error: np.float64 = mean_squared_error(y_true=w_validate_target_y, y_pred=model_predict)
  print(f"  Mean_squared_error (MSE): {model_mean_squared_error}")

  model_mean_absolute_error: np.float64 = mean_absolute_error(y_true=w_validate_target_y, y_pred=model_predict)
  print(f" Mean_absolute_error (MAE): {model_mean_absolute_error}")

  print("'"*50)
  return model

  # save_model_to_drive(model=model, model_name=f"{str(model_r2)[:6]}{name}")

## SCALER
white_wine_min_max_scaler: MinMaxScaler = MinMaxScaler().fit(X=white_wine_df_train_part)
# white_wine_standard_scaler: StandardScaler = StandardScaler().fit(X=white_wine_df_train_part)

### ****** LINEARREGRESSION. FOR white WINE ******
white_wine_linear_clean_regressor: LinearRegression = w_create_model(
    regressor=LinearRegression(),
    name="white_wine_linear_clean_regressor",
    scaler=white_wine_min_max_scaler
)

### ****** LINEARREGRESSION WITH HYPER PARAMS. FOR white WINE ******
white_wine_linear_hyper_params_regressor: LinearRegression = w_create_model(
    # regressor=LinearRegression(n_jobs=-1),
    # regressor=LinearRegression(positive=True),
    regressor=LinearRegression(fit_intercept=False),
    name="white_wine_linear_hyper_params_regressor",
    scaler=white_wine_min_max_scaler
)

### ****** SGDRegressor. FOR white WINE ******
white_wine_clean_sgdegressor: SGDRegressor = w_create_model(
    regressor=SGDRegressor(),
    name="white_wine_clean_sgdegressor",
    scaler=white_wine_min_max_scaler
)

### ****** SGDRegressor WITH HYPER PARAMS. FOR white WINE ******
white_wine_hyper_params_sgdegressor: SGDRegressor = w_create_model(
    regressor=SGDRegressor(loss="squared_epsilon_insensitive", penalty="elasticnet", tol=1e-5, n_iter_no_change=15), # better than clean
    name="white_wine_hyper_params_sgdegressor",
    scaler=white_wine_min_max_scaler
)

### ****** MINI BATCH SGDRegressor. FOR white WINE ******
white_wine_clean_mb_sgdegressor: SGDRegressor = w_create_model(
    regressor=SGDRegressor(),
    name="white_wine_clean_mb_sgdegressor",
    scaler=white_wine_min_max_scaler,
    partial=True
)

### ****** MINI BATCH SGDRegressor WITH HYPER PARAMS. FOR white WINE ******
white_wine_hyper_params_mb_sgdegressor: SGDRegressor = w_create_model(
    regressor=SGDRegressor(loss="squared_epsilon_insensitive", penalty="elasticnet", tol=1e-5, n_iter_no_change=15),
    name="white_wine_hyper_params_mb_sgdegressor",
    scaler=white_wine_min_max_scaler,
    partial=True
)

### ****** ElasticNet. FOR white WINE ******
white_wine_clean_elastic_net: ElasticNet = w_create_model(
    regressor=ElasticNet(),
    name="white_wine_clean_elastic_net",
    scaler=white_wine_min_max_scaler
)

### ****** ElasticNet WITH HYPER PARAMS. FOR white WINE ******
white_wine_hyper_params_elastic_net: ElasticNet = w_create_model(
    regressor=ElasticNet(tol=1e-8, l1_ratio=0.2),
    name="white_wine_hyper_params_elastic_net",
    scaler=white_wine_min_max_scaler
)

### ****** Lasso. FOR white WINE ******
white_wine_clean_l1: Lasso = w_create_model(
    regressor=Lasso(),
    name="white_wine_clean_l1",
    scaler=white_wine_min_max_scaler
)

### ****** Lasso WITH HYPER PARAMS. FOR white WINE ******
white_wine_hyper_params_l1: Lasso = w_create_model(
    regressor=Lasso(alpha=0.5, tol=1e-6),
    name="white_wine_hyper_params_l1",
    scaler=white_wine_min_max_scaler
)

def w_value_results(model, name:str):
  print("'"*50)
  print(name)
  model_predict = model.predict(X=w_test_features_X)

  ## Metrics
  model_r2: np.float64 = r2_score(y_true=w_test_target_y, y_pred=model_predict)
  print(f"                        R2: {model_r2}")

  model_mean_squared_error: np.float64 = mean_squared_error(y_true=w_test_target_y, y_pred=model_predict)
  print(f"  Mean_squared_error (MSE): {model_mean_squared_error}")

  model_mean_absolute_error: np.float64 = mean_absolute_error(y_true=w_test_target_y, y_pred=model_predict)
  print(f" Mean_absolute_error (MAE): {model_mean_absolute_error}")
  print("'"*50)

### Оцінка результатів
w_value_results(model=white_wine_linear_clean_regressor, name="white_wine_linear_clean_regressor")
w_value_results(model=white_wine_linear_hyper_params_regressor, name="white_wine_linear_hyper_params_regressor")
w_value_results(model=white_wine_clean_sgdegressor, name="white_wine_clean_sgdegressor")
w_value_results(model=white_wine_hyper_params_sgdegressor, name="white_wine_hyper_params_sgdegressor")
w_value_results(model=white_wine_clean_mb_sgdegressor, name="white_wine_clean_mb_sgdegressor")
w_value_results(model=white_wine_hyper_params_mb_sgdegressor, name="white_wine_hyper_params_mb_sgdegressor")
w_value_results(model=white_wine_clean_elastic_net, name="white_wine_clean_elastic_net")
w_value_results(model=white_wine_hyper_params_elastic_net, name="white_wine_hyper_params_elastic_net")
w_value_results(model=white_wine_clean_l1, name="white_wine_clean_l1")
w_value_results(model=white_wine_hyper_params_l1, name="white_wine_hyper_params_l1")

